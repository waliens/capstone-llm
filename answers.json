{"items": [{"owner": {"account_id": 14978309, "reputation": 5475, "user_id": 10813082, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/ca15107337874ba34a3a4f80707faa89?s=256&d=identicon&r=PG", "display_name": "tconbeer", "link": "https://stackoverflow.com/users/10813082/tconbeer"}, "is_accepted": false, "score": 28, "last_activity_date": 1721156507, "last_edit_date": 1721156507, "creation_date": 1657726145, "answer_id": 72968861, "question_id": 72956095, "content_license": "CC BY-SA 4.0", "body": "<p><code>var</code> and <code>env_var</code> are two separate features of dbt.</p>\n<p>You can use <code>var</code> to access a global variable you define in your <code>dbt_project.yml</code> file. The <code>--vars</code> command-line option lets you override the values of these vars at runtime. See the <a href=\"https://docs.getdbt.com/reference/dbt-jinja-functions/var\" rel=\"nofollow noreferrer\">docs for <code>var</code></a>.</p>\n<p>You should use <code>env_var</code> to access <a href=\"https://www.techrepublic.com/article/linux-101-what-are-environment-variables/\" rel=\"nofollow noreferrer\">environment variables</a> that you set outside of dbt for your system, user, or shell session. Typically you would use environment variables to store secrets like your profile's connection credentials.</p>\n<p>To access environment variables in your <code>profiles.yml</code> file, you replace the values for username and password with a call to the <code>env_var</code> macro, as they do in the <a href=\"https://docs.getdbt.com/reference/dbt-jinja-functions/env_var\" rel=\"nofollow noreferrer\">docs for <code>env_var</code></a>:</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>profile:\n  target: prod\n  outputs:\n    prod:\n      type: postgres\n      host: 127.0.0.1\n      # IMPORTANT: Make sure to quote the entire Jinja string here\n      user: &quot;{{ env_var('DBT_USER') }}&quot;\n      password: &quot;{{ env_var('DBT_PASSWORD') }}&quot;\n      ....\n</code></pre>\n<p>Then BEFORE you issue the <code>dbt_run</code> command, you need to set the <code>DBT_USER</code> and <code>DBT_PASSWORD</code> environment variables for your system, user, or shell session. This will depend on your OS, but there are lots of good instructions on this. To set a var for your shell session (for Unix OSes), that could look like this:</p>\n<pre class=\"lang-bash prettyprint-override\"><code>$ export DBT_USER=my_username\n$ export DBT_PASSWORD=abc123\n$ dbt run\n</code></pre>\n<p>Note that storing passwords in environment variables isn't necessarily more secure than keeping them in your <code>profiles.yml</code> file, since they're stored in plaintext and not protected from being dumped into logs, etc. (You shouldn't be checking <code>profiles.yml</code> into source control). You should consider at least using an environment variable name prefixed by <code>DBT_ENV_SECRET_</code> so that dbt keeps them out of logs. See <a href=\"https://docs.getdbt.com/reference/dbt-jinja-functions/env_var#secrets\" rel=\"nofollow noreferrer\">the docs</a> for more info</p>\n"}, {"owner": {"account_id": 11566973, "reputation": 10796, "user_id": 8474917, "user_type": "registered", "profile_image": "https://i.sstatic.net/KOXGe.jpg?s=256", "display_name": "Adam Kipnis", "link": "https://stackoverflow.com/users/8474917/adam-kipnis"}, "is_accepted": false, "score": 25, "last_activity_date": 1663956949, "creation_date": 1663956949, "answer_id": 73831542, "question_id": 73784913, "content_license": "CC BY-SA 4.0", "body": "<p>Using <code>ref</code> creates the lineage for your DAG and will run the predecessor models. Using <code>source</code> references a base table that is not necessarily a model. Rule of thumb is use <code>source</code> in your base models and everything else should use <code>ref</code>.</p>\n<p>Example - Green nodes represent tables ingested into your DWH. The blue/red nodes are DBT models.\n<a href=\"https://i.sstatic.net/n7R7I.png\" rel=\"noreferrer\"><img src=\"https://i.sstatic.net/n7R7I.png\" alt=\"enter image description here\" /></a></p>\n"}, {"owner": {"account_id": 3391941, "reputation": 561, "user_id": 2846588, "user_type": "registered", "profile_image": "https://i.sstatic.net/H5rZ9.png?s=256", "display_name": "Stephan", "link": "https://stackoverflow.com/users/2846588/stephan"}, "is_accepted": true, "score": 21, "last_activity_date": 1704753498, "last_edit_date": 1704753498, "creation_date": 1593627697, "answer_id": 62683107, "question_id": 62675644, "content_license": "CC BY-SA 4.0", "body": "<p>You could use <a href=\"https://github.com/dbt-labs/dbt-utils#expression_is_true-source\" rel=\"nofollow noreferrer\"><code>dbt_utils.expression_is_true</code></a></p>\n<pre><code>version: 2\n\nmodels:\n  - name: model_name\n    tests:\n      - dbt_utils.expression_is_true:\n          expression: &quot;col_a &gt; 0&quot;\n</code></pre>\n"}, {"owner": {"account_id": 516334, "reputation": 4994, "user_id": 1680826, "user_type": "registered", "accept_rate": 60, "profile_image": "https://i.sstatic.net/bh4mH.jpg?s=256", "display_name": "botchniaque", "link": "https://stackoverflow.com/users/1680826/botchniaque"}, "is_accepted": true, "score": 21, "last_activity_date": 1656497307, "creation_date": 1656497307, "answer_id": 72799561, "question_id": 72799237, "content_license": "CC BY-SA 4.0", "body": "<p>Dbt allows syntax of</p>\n<ul>\n<li>selecting a node <em>and all nodes it requires</em> (<code>+</code> before the model name)</li>\n<li>selecting a node <em>and all nodes that depend on it</em> (<code>+</code> after the model name)</li>\n<li>you can also do both (<code>+model_name+</code>)</li>\n</ul>\n<p>In your case <code>dbt run --select +forecast</code> should do the trick</p>\n<p>Also check the <a href=\"https://docs.getdbt.com/reference/node-selection/graph-operators#the-plus-operator\" rel=\"noreferrer\">documentation of <em>the <code>+</code> operator</em></a>.</p>\n"}, {"owner": {"account_id": 85788, "reputation": 1222, "user_id": 238968, "user_type": "registered", "accept_rate": 73, "profile_image": "https://www.gravatar.com/avatar/2634b26733c03daf1532b78b84e2be3b?s=256&d=identicon&r=PG", "display_name": "Ravi", "link": "https://stackoverflow.com/users/238968/ravi"}, "is_accepted": true, "score": 20, "last_activity_date": 1610040206, "creation_date": 1610040206, "answer_id": 65617106, "question_id": 65614108, "content_license": "CC BY-SA 4.0", "body": "<p>I got this working eventually. Have to put the variable name within the <strong>var()</strong></p>\n<pre><code>SELECT \n*\nFROM\n{% if var('enable_whitelisting') == 'true' %}\n    {{ ref('accounts_whitelisted') }}    accounts\n{% else %}\n        {{ ref('accounts') }}   accounts\n{% endif %}\n</code></pre>\n"}, {"owner": {"account_id": 4753087, "reputation": 3892, "user_id": 3842610, "user_type": "registered", "accept_rate": 75, "profile_image": "https://i.sstatic.net/WXMEe.jpg?s=256", "display_name": "Anders Swanson", "link": "https://stackoverflow.com/users/3842610/anders-swanson"}, "is_accepted": true, "score": 20, "last_activity_date": 1635190091, "creation_date": 1635190091, "answer_id": 69713706, "question_id": 69713087, "content_license": "CC BY-SA 4.0", "body": "<p>You are very close! I'm 96% sure that this is an indentation issue -- the #1 pain point of working with YAML. The solution is that both <code>to</code> and <code>field</code> need to be indented below the <code>relationships</code> key as opposed to at the same level.</p>\n<p>See the <a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/tests/#generic-tests\" rel=\"noreferrer\">Tests dbt docs page</a> for an example</p>\n<pre class=\"lang-yaml prettyprint-override\"><code>  - name: PROTOCOL_ID\n    tests:\n      - relationships:\n          to: ref('Animal_Protocols')\n          field: id\n</code></pre>\n"}, {"owner": {"account_id": 2799357, "reputation": 488, "user_id": 4583536, "user_type": "registered", "profile_image": "https://lh6.googleusercontent.com/-TDydrQ6fWJI/AAAAAAAAAAI/AAAAAAAAAK4/55nXmm-L7CY/photo.jpg?sz=256", "display_name": "David Clarance", "link": "https://stackoverflow.com/users/4583536/david-clarance"}, "is_accepted": true, "score": 19, "last_activity_date": 1634104357, "creation_date": 1634104357, "answer_id": 69550357, "question_id": 69550294, "content_license": "CC BY-SA 4.0", "body": "<p>dbt docs might be what you're looking for?</p>\n<p>You need to first generate the docs using:</p>\n<p><code> dbt docs generate</code></p>\n<p>Then, serve them:</p>\n<p><code>dbt docs serve</code></p>\n<p>You'll find that the docs are served locally. Once you open the link in a browser you can see the lineage at the bottom right like so:</p>\n<p><a href=\"https://i.sstatic.net/rDhEZ.png\" rel=\"noreferrer\"><img src=\"https://i.sstatic.net/rDhEZ.png\" alt=\"enter image description here\" /></a></p>\n<p>There is more detail here: <a href=\"https://docs.getdbt.com/reference/commands/cmd-docs\" rel=\"noreferrer\">https://docs.getdbt.com/reference/commands/cmd-docs</a></p>\n"}, {"owner": {"account_id": 18318689, "reputation": 391, "user_id": 13339947, "user_type": "registered", "profile_image": "https://i.sstatic.net/3SRqm.jpg?s=256", "display_name": "dylanbaker", "link": "https://stackoverflow.com/users/13339947/dylanbaker"}, "is_accepted": true, "score": 18, "last_activity_date": 1603458555, "last_edit_date": 1603458555, "creation_date": 1603398523, "answer_id": 64490072, "question_id": 64489772, "content_license": "CC BY-SA 4.0", "body": "<p>dbt doesn't support materialized views, as far as I'm aware, but as Felipe commented, there is an <a href=\"https://github.com/fishtown-analytics/dbt/issues/1162\" rel=\"noreferrer\">open issue to discuss it</a>. If it <em>were</em> possible to use materialized views on Snowflake, you're right that they <em>somewhat</em> become the same thing. The materialized view would update even if you haven't run dbt. As Drew mentions in the ticket though, there are a lot of caveats that make using tables with dbt preferable in most use cases: &quot;no window functions, no unions, limited aggregates, can't query views, etc etc etc&quot;.</p>\n<p>That said, dbt does support views and tables.</p>\n<p>Even when you're using dbt, there's still a difference between a view and a table. A table will always need to be refreshed by dbt in order to be updated. A view will always be as up-to-date as the underlying tables it is referencing.</p>\n<p>For example, let's say you have a dbt model called <code>fct_orders</code> which references a table that is loaded by Fivetran/Stitch called <code>shopify.order</code>. If your model is materialized as a view, it will always return the most up-to-date data in the Shopify table. If it is materialized as a table, and new data has arrived in the Shopify table since you last run dbt, the model will be 'stale'.</p>\n<p>That said, the benefit of materializing it as a table is that it will run more quickly, given it's not having to do the SQL 'transformation' each time.</p>\n<p>The advice I have seen given most often is something like this:</p>\n<ul>\n<li>If using a view isn't too slow for your end-users, use a view.</li>\n<li>If a view gets too slow for your end-users, use a table.</li>\n<li>If building a table with dbt gets too slow, use incremental models in dbt.</li>\n</ul>\n"}, {"owner": {"account_id": 9471026, "reputation": 5411, "user_id": 7041871, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/215d7eecd94e70508238b9959791176e?s=256&d=identicon&r=PG&f=y&so-version=2", "display_name": "Javier Mont&#243;n", "link": "https://stackoverflow.com/users/7041871/javier-mont%c3%b3n"}, "is_accepted": false, "score": 17, "last_activity_date": 1600769531, "creation_date": 1600769531, "answer_id": 64007574, "question_id": 64007239, "content_license": "CC BY-SA 4.0", "body": "<p>You can use <code>call statement</code> and get the result in a variable with <code>load_result</code></p>\n<p>Here is an example of retrieving only one field from the select statement:</p>\n<pre><code>{%- call statement('my_statement', fetch_result=True) -%}\n      SELECT my_field FROM my_table\n{%- endcall -%}\n\n{%- set my_var = load_result('my_statement')['data'][0][0] -%}\n</code></pre>\n<p>Then you can use <code>{{ my_var }}</code></p>\n<p>You can play with <code>['data'][0][0]</code> depending on the rows and columns that your select returns</p>\n"}, {"owner": {"account_id": 412955, "reputation": 13560, "user_id": 786326, "user_type": "registered", "accept_rate": 79, "profile_image": "https://i.sstatic.net/FQSbb.jpg?s=256", "display_name": "Shankar ARUL", "link": "https://stackoverflow.com/users/786326/shankar-arul"}, "is_accepted": false, "score": 17, "last_activity_date": 1678889080, "creation_date": 1678889080, "answer_id": 75745820, "question_id": 72799237, "content_license": "CC BY-SA 4.0", "body": "<p>In addition to the <a href=\"https://docs.getdbt.com/reference/node-selection/graph-operators#the-plus-operator\" rel=\"noreferrer\">+ operator</a>, incase you just need to run multiple unrelated models by specifying their names, you can do so <a href=\"https://docs.getdbt.com/reference/node-selection/syntax\" rel=\"noreferrer\">as such</a>:</p>\n<pre><code>dbt run --select my_first_model my_second_model\n</code></pre>\n"}, {"owner": {"account_id": 3505202, "reputation": 759, "user_id": 2930873, "user_type": "registered", "profile_image": "https://graph.facebook.com/785113691/picture?type=large", "display_name": "Claire Carroll", "link": "https://stackoverflow.com/users/2930873/claire-carroll"}, "is_accepted": false, "score": 16, "last_activity_date": 1595514673, "creation_date": 1595514673, "answer_id": 63056701, "question_id": 63002171, "content_license": "CC BY-SA 4.0", "body": "<p>To use dbt, you need to already be able to <code>select from</code> your raw data in your warehouse.</p>\n<p>In general, dbt is not an ETL tool:</p>\n<blockquote>\n<p><em>[dbt] doesn\u2019t extract or load data, but it\u2019s extremely good at transforming data that\u2019s already loaded into your warehouse. This \u201ctransform after load\u201d architecture is becoming known as ELT (extract, load, transform). <strong>dbt is the T in ELT.</strong> [<a href=\"https://blog.getdbt.com/what--exactly--is-dbt-/\" rel=\"noreferrer\">reference</a>]</em></p>\n</blockquote>\n<p>So no, you cannot use dbt with Redshift and Deltalake at the same time. Instead, use a separate service to extract and load data into your Redshift cluster \u2014 dbt is agnostic about which tool you use to do this.</p>\n<p>There is a nuance to this answer - you <em>could</em> use dbt to select from external files in S3 or GCS, so long as you've set up your data warehouse to be able to read those files. For Redshift, this means setting up <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/c-getting-started-using-spectrum.html\" rel=\"noreferrer\">Redshift Spectrum</a>. (For Snowflake, this means setting up an <a href=\"https://docs.snowflake.com/en/sql-reference/sql/create-external-table.html\" rel=\"noreferrer\">external table</a> and on BigQuery, you can also <a href=\"https://cloud.google.com/bigquery/external-data-cloud-storage\" rel=\"noreferrer\">query cloud storage data</a>)</p>\n<p>So, if the data you read in Deltalake lives in S3, if you set up your Redshift cluster to be able to read it, you can use dbt to transform the data!</p>\n"}, {"owner": {"account_id": 1589838, "reputation": 626, "user_id": 2417108, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/66629f81d5bfb58104800809c206d73c?s=256&d=identicon&r=PG", "display_name": "Pawel", "link": "https://stackoverflow.com/users/2417108/pawel"}, "is_accepted": false, "score": 16, "last_activity_date": 1597821701, "creation_date": 1597821701, "answer_id": 63481884, "question_id": 63478564, "content_license": "CC BY-SA 4.0", "body": "<p>I have created such a macro in an older version of dbt and it still works on 0.17.1.</p>\n<p>The macro below <code>item_in_list_query</code> is getting a list of <code>tables</code> from a separate macro <code>get_tables</code> (also below). That list of tables is then concatenated inside <code>item_in_list_query</code> to compose a desired SQL query and execute it. For demonstration there is also a model in which <code>item_in_list_query</code> is used.</p>\n<h3>item_in_list_query</h3>\n<pre><code>{% macro item_in_list_query() %}\n\n    {% set tables = get_tables() %}\n\n    {{ log(&quot;Tables: &quot; ~ tables, True) }}\n\n    {% set query %}\n        select id\n        from my_tables\n        {% if tables -%}\n            where lower(table_name) in {% for t in tables -%} {{ t }} {%- endfor -%}\n        {%- endif -%}\n    {% endset %}\n\n    {{ log(&quot;query: &quot; ~ query, True) }}\n\n    {# run_query returns agate.Table (https://agate.readthedocs.io/en/1.6.1/api/table.html). #}\n    {% set results = run_query(query) %}\n\n    {{ log(&quot;results: &quot; ~ results, True) }}\n\n    {# execute is a Jinja variable that returns True when dbt is in &quot;execute&quot; mode i.e. True when running dbt run but False during dbt compile. #}\n    {% if execute %}\n    {# agate.table.rows is agate.MappedSequence in which data that can be accessed either by numeric index or by key. #}\n    {% set results_list = results.rows %}\n    {% else %}\n    {% set results_list = [] %}\n    {% endif %}\n\n    {{ log(&quot;results_list: &quot; ~ results_list, True) }}\n    {{ return(results_list) }}\n\n{% endmacro %}\n\n</code></pre>\n<h3>get_tables</h3>\n<pre><code>{% macro get_tables() %}\n      {%- set tables = [\n          ('table1', 'table2')\n      ] -%}\n  {{return(tables )}}\n{% endmacro %}\n\n</code></pre>\n<h3>model</h3>\n<pre><code>{%- for item in item_in_list_query() -%}\n  {%- if not loop.first %} UNION ALL {% endif %}\n  select {{ item.id }}\n{%- endfor -%}\n\n</code></pre>\n"}, {"owner": {"account_id": 5797626, "reputation": 353, "user_id": 4572922, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/c09144ee2bdfa7142743fa1a8fd430a6?s=256&d=identicon&r=PG&f=y&so-version=2", "display_name": "Thomas Dickson", "link": "https://stackoverflow.com/users/4572922/thomas-dickson"}, "is_accepted": false, "score": 16, "last_activity_date": 1623311062, "creation_date": 1623311062, "answer_id": 67916817, "question_id": 62742369, "content_license": "CC BY-SA 4.0", "body": "<p>There are a few different approaches to solving to this problem:</p>\n<ol>\n<li>Check the profile key in your <code>dbt_project.yml</code></li>\n<li>Check the profiles you have in your <code>profiles.yml</code></li>\n<li>Run <code>dbt debug --config-dir</code> to check where dbt thinks your config file is.</li>\n</ol>\n<p>See the dbt documentation <a href=\"https://docs.getdbt.com/docs/guides/debugging-errors#could-not-find-profile\" rel=\"noreferrer\">here</a></p>\n"}, {"owner": {"account_id": 3505202, "reputation": 759, "user_id": 2930873, "user_type": "registered", "profile_image": "https://graph.facebook.com/785113691/picture?type=large", "display_name": "Claire Carroll", "link": "https://stackoverflow.com/users/2930873/claire-carroll"}, "is_accepted": false, "score": 14, "last_activity_date": 1595521139, "last_edit_date": 1595521139, "creation_date": 1595512091, "answer_id": 63055840, "question_id": 63001872, "content_license": "CC BY-SA 4.0", "body": "<p>You're right in thinking that dbt does not support temporary tables. That's because temporary tables only persist in a single session, and dbt opens one connection/session per thread. Therefore any temporary tables created on one thread would not be visible to a model running on a different thread.</p>\n<p>It sounds like CTEs are a performance drag for you though \u2014 out of interest, which warehouse are you using?</p>\n<p>You've identified two workarounds, and there's another one worth discussing:</p>\n<p><strong>Option 1: Materialize your model as CTEs using the <code>ephemeral</code> materialization (<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/materializations/#ephemeral\" rel=\"noreferrer\">docs</a>)</strong></p>\n<p><em>Pros:</em></p>\n<ul>\n<li>The models show up in the lineage graph</li>\n<li>You can re-use these transformations in multiple downstream models by <code>ref</code>-ing them</li>\n<li>You can test and document these models</li>\n</ul>\n<p><em>Cons:</em></p>\n<ul>\n<li>At some point there is a performance degradation with too many stacked CTEs (especially on older versions of postgres, where CTEs are an optimization fence)</li>\n<li>Compiled SQL can be harder to debug</li>\n</ul>\n<p><strong>Option 2: Use pre-hooks to create temp tables</strong></p>\n<p>I would generally recommend against this \u2014 you can't test or document your models, and they won't be in the lineage graph (as you've noted).</p>\n<p><strong>Option 3: Materialize these models as tables in a separate schema, and drop the schema at the end of a run</strong></p>\n<p>I think Michael's suggestion is a good one! I'd tweak it just a little bit:</p>\n<ol>\n<li>Use the <a href=\"https://docs.getdbt.com/reference/resource-configs/schema/\" rel=\"noreferrer\">schema</a> config to materialize a model in a separate schema</li>\n</ol>\n<pre><code>{{ config(\n  materialized='table',\n  schema='my_temporary_schema'\n) }}\n</code></pre>\n<ol start=\"2\">\n<li>Then, at the end of a run, use an <code>on-run-end</code> hook (<a href=\"https://docs.getdbt.com/reference/project-configs/on-run-start-on-run-end/\" rel=\"noreferrer\">docs</a>) to drop that schema \u2014 in your <code>dbt_project.yml</code>:</li>\n</ol>\n<pre><code>on-run-end: &quot;drop schema my_temporary_schema cascade&quot;\n</code></pre>\n<p><em>Pros:</em></p>\n<ul>\n<li>All the benefits of Option 1</li>\n<li>Sounds like it might be more performant than using CTEs</li>\n</ul>\n<p><em>Cons:</em></p>\n<ul>\n<li>Make sure you don't have any dependent views on top of that schema! They might get dropped when you run a <code>drop cascade</code> command! This introduces fragility into your project!</li>\n</ul>\n"}, {"owner": {"account_id": 19119069, "reputation": 981, "user_id": 13963390, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GjyuXth9ZhlTqIsWqs-YeN0og3rSjdK7Sb1yBxc=k-s256", "display_name": "Jeremy Cohen", "link": "https://stackoverflow.com/users/13963390/jeremy-cohen"}, "is_accepted": true, "score": 14, "last_activity_date": 1608566020, "creation_date": 1608566020, "answer_id": 65395870, "question_id": 65395382, "content_license": "CC BY-SA 4.0", "body": "<p>Check out the <a href=\"https://docs.getdbt.com/reference/node-selection/set-operators/#intersections\" rel=\"noreferrer\">intersection operator</a>. It's new in dbt v0.18, and it's for this use case exactly.</p>\n<pre><code>dbt run -m tag:mixpanel_tests,tag:quality\n</code></pre>\n"}, {"owner": {"account_id": 6957722, "reputation": 720, "user_id": 5338256, "user_type": "registered", "accept_rate": 21, "profile_image": "https://www.gravatar.com/avatar/e238a7553e3588046d5856983bf26d38?s=256&d=identicon&r=PG&f=y&so-version=2", "display_name": "Michal", "link": "https://stackoverflow.com/users/5338256/michal"}, "is_accepted": false, "score": 14, "last_activity_date": 1668417420, "creation_date": 1668417420, "answer_id": 74429311, "question_id": 71577610, "content_license": "CC BY-SA 4.0", "body": "<p>In my case, I had to execute first</p>\n\n<pre><code>dbt docs generate\n</code></pre>\n<p>and then</p>\n\n<pre><code>dbt docs serve\n</code></pre>\n<p>which started localhost with desired docs. It was run under dbt=1.3.0</p>\n"}, {"owner": {"account_id": 14978309, "reputation": 5475, "user_id": 10813082, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/ca15107337874ba34a3a4f80707faa89?s=256&d=identicon&r=PG", "display_name": "tconbeer", "link": "https://stackoverflow.com/users/10813082/tconbeer"}, "is_accepted": true, "score": 14, "last_activity_date": 1682610092, "last_edit_date": 1682610092, "creation_date": 1673630837, "answer_id": 75112535, "question_id": 75111217, "content_license": "CC BY-SA 4.0", "body": "<h2>Update: v1.5 has arrived!</h2>\n<p>With v1.5 of dbt, we get a stable and officially supported Python API for invoking dbt operations; this API has functional parity with the CLI.</p>\n<p>From the <a href=\"https://docs.getdbt.com/reference/programmatic-invocations\" rel=\"noreferrer\">docs</a>:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from dbt.cli.main import dbtRunner, dbtRunnerResult\n\n# initialize\ndbt = dbtRunner()\n\n# create CLI args as a list of strings\ncli_args = [&quot;run&quot;, &quot;--select&quot;, &quot;tag:my_tag&quot;]\n\n# run the command\nres: dbtRunnerResult = dbt.invoke(cli_args)\n\n# inspect the results\nfor r in res.result:\n    print(f&quot;{r.node.name}: {r.status}&quot;)\n</code></pre>\n<p>There are some caveats about the stability of artifacts returned by <code>dbt.invoke</code>; read the docs for more details.</p>\n<h2>Original Answer</h2>\n<p>(As of Jan 2023) There is not a public Python API for dbt, yet. It is expected in v1.5, which should be out in a couple months.</p>\n<p>Right now, your safest option is to use the CLI. If you don't want to use <code>subprocess</code>, the CLI uses <a href=\"https://click.palletsprojects.com/en/8.1.x/\" rel=\"noreferrer\">Click</a> now, and Click provides a <a href=\"https://click.palletsprojects.com/en/8.1.x/api/#click.testing.CliRunner\" rel=\"noreferrer\">runner</a> that you can use to invoke Click commands. It's usually used for testing, but I think it would work for your use case, too. The CLI command is <a href=\"https://github.com/dbt-labs/dbt-core/blob/7077c475511b4f251245b6e246b9a23bed18eed0/core/dbt/cli/main.py#L292\" rel=\"noreferrer\">here</a>. That would look something like:</p>\n<pre class=\"lang-py prettyprint-override\"><code>from click.testing import CliRunner\nfrom dbt.cli.main import run\n\ndbt_runner = CliRunner()\ndbt_runner.invoke(run, args=&quot;-s my_model&quot;)\n</code></pre>\n<p>You could also invoke dbt the way they do in the test suite, using <a href=\"https://github.com/dbt-labs/dbt-core/blob/1e35339389ded85631128b66f57c62ca60649c88/core/dbt/tests/util.py#L63\" rel=\"noreferrer\"><code>run_dbt</code></a>.</p>\n"}, {"owner": {"account_id": 4304114, "reputation": 5021, "user_id": 3517025, "user_type": "registered", "accept_rate": 73, "profile_image": "https://www.gravatar.com/avatar/e2bedb3a3b004340531b316094a000d8?s=256&d=identicon&r=PG", "display_name": "Joey Baruch", "link": "https://stackoverflow.com/users/3517025/joey-baruch"}, "is_accepted": true, "score": 13, "last_activity_date": 1635536706, "creation_date": 1635536706, "answer_id": 69774042, "question_id": 66061826, "content_license": "CC BY-SA 4.0", "body": "<p>From <a href=\"https://docs.getdbt.com/reference/resource-configs/postgres-configs#indexes\" rel=\"noreferrer\">dbt docs</a>:</p>\n<pre class=\"lang-sql prettyprint-override\"><code>{{ config(\n    materialized = 'table',\n    indexes=[\n      {'columns': ['column_a'], 'type': 'hash'},\n      {'columns': ['column_a', 'column_b'], 'unique': True},\n    ]\n)}}\n\nselect ...\n</code></pre>\n"}, {"owner": {"account_id": 2852794, "reputation": 1757, "user_id": 2449617, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/10531d02ab01ab176e55601422618aef?s=256&d=identicon&r=PG", "display_name": "ifoukarakis", "link": "https://stackoverflow.com/users/2449617/ifoukarakis"}, "is_accepted": false, "score": 13, "last_activity_date": 1679387278, "creation_date": 1679387278, "answer_id": 75798816, "question_id": 62675644, "content_license": "CC BY-SA 4.0", "body": "<p>Previous answer is correct. Another option is <a href=\"https://github.com/dbt-labs/dbt-utils#accepted_range-source\" rel=\"noreferrer\">accepted_range</a>:</p>\n<pre><code>version: 2\n\nmodels:\n  - name: model_name\n    columns:\n      - name: user_id\n        tests:\n          - dbt_utils.accepted_range:\n              min_value: 0\n              inclusive: false\n</code></pre>\n"}, {"owner": {"account_id": 9002381, "reputation": 1300, "user_id": 6710525, "user_type": "registered", "profile_image": "https://i.sstatic.net/4oLy6.jpg?s=256", "display_name": "totooooo", "link": "https://stackoverflow.com/users/6710525/totooooo"}, "is_accepted": true, "score": 12, "last_activity_date": 1624027277, "last_edit_date": 1624027277, "creation_date": 1583509836, "answer_id": 60567491, "question_id": 60565688, "content_license": "CC BY-SA 4.0", "body": "<p>Just got answered on the dbt slack.</p>\n<p>The file just contains a cookie for dbt's anonymous usage tracking. It happened to land in my repo because I placed my <code>profiles.yml</code> in my repo. (my credentials are in environment variables). But normally it's rather created in <code>~/.dbt</code></p>\n"}, {"owner": {"account_id": 19119069, "reputation": 981, "user_id": 13963390, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GjyuXth9ZhlTqIsWqs-YeN0og3rSjdK7Sb1yBxc=k-s256", "display_name": "Jeremy Cohen", "link": "https://stackoverflow.com/users/13963390/jeremy-cohen"}, "is_accepted": true, "score": 12, "last_activity_date": 1596210421, "last_edit_date": 1596210421, "creation_date": 1595250419, "answer_id": 62996073, "question_id": 62992304, "content_license": "CC BY-SA 4.0", "body": "<p>As the maintainer of the <code>dbt-external-tables</code> package, I'll share its opinionated view. The package believes that you should stage all external sources (S3 files) as external tables or with snowpipes <em>first</em>, in a process that includes as little confounding logic as possible. Then you can select from them, as sources, in dbt models, alongside all requisite business logic.</p>\n<p>If my understanding is correct, you would stage your mixpanel data as below, in a file called (e.g.) <em>models/staging/mixpanel/src_mixpanel.yml</em>:</p>\n<pre><code>version: 2\n\nsources:\n\n  - name: s3_mixpanel\n    database: raw_dev\n    tables:\n      - name: events\n        external:\n          location: '@my_s3_stage'\n          file_format: &quot;( type = json )&quot;  # or a named file format\n          auto_refresh: false # depends on your S3 setup\n          partitions:\n            - name: event_date\n              expression: to_date(SUBSTR(metadata$filename,16,10),'yyyy/mm/dd')\n          columns:\n            - name: properties\n              data_type: variant\n</code></pre>\n<p>You would run this macro from the package to create the external table\u2014and, after creation, to update its partition metadata if you don't have <code>auto_refresh</code> enabled (see Snowflake <a href=\"https://docs.snowflake.com/en/sql-reference/sql/create-external-table.html\" rel=\"noreferrer\">docs</a>):</p>\n<pre><code>dbt run-operation stage_external_sources\n</code></pre>\n<p>You can then select from this source in an incremental model, like the one you have above. Now, <code>event_date</code> is a partition column on this external table, so filtering on it <strong>should</strong> enable Snowflake to prune files (though that's been inconsistent historically for dynamic, subquery-derived filters).</p>\n<pre><code>{{\n  config(\n    materialized ='incremental'\n  )\n}}\n \n  SELECT\n    metadata$filename as file_name,\n    event_date,\n    value as payload,\n    properties:mp_processing_time_ms::int / 1000 as event_timestamp_converted,\n    CONVERT_TIMEZONE('Europe/London', current_timestamp) as modeled_at\n\n from {{ source('s3_mixpanel', 'events' }} \n\n    \n{% if is_incremental() %}\n    -- this filter will only be applied on an incremental run\n    WHERE event_date &gt;(\n    SELECT\n        max(event_date)\n    FROM\n        {{ this }}\n    )\n{% endif %}\n\n{{ row_limit() }}\n</code></pre>\n"}, {"owner": {"account_id": 4727284, "reputation": 5592, "user_id": 3823815, "user_type": "registered", "profile_image": "https://i.sstatic.net/5xNDK.jpg?s=256", "display_name": "louis_guitton", "link": "https://stackoverflow.com/users/3823815/louis-guitton"}, "is_accepted": true, "score": 12, "last_activity_date": 1609067416, "creation_date": 1609067416, "answer_id": 65465102, "question_id": 65464756, "content_license": "CC BY-SA 4.0", "body": "<p>Judging by your questions, you would benefit from trying to dockerise dbt on its own, independently from airflow. A lot of your questions would disappear. But here are my answers anyway.</p>\n<ol>\n<li>\n<blockquote>\n<p>Should DBT as a whole project be run as one Docker container, or is it broken down? (for example: are tests ran as a separate container from dbt tasks?)</p>\n</blockquote>\n</li>\n</ol>\n<p>I suggest you build one docker image for the entire project. The docker image can be based on the python image since dbt is a python CLI tool. You then use the CMD arguments of the docker image to run any dbt command you would run outside docker.\nPlease remember the syntax of <code>docker run</code> (which has nothing to do with dbt): you can specify any COMMAND you wand to run at invocation time</p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]\n</code></pre>\n<p>Also, the first hit on Google for &quot;docker dbt&quot; is <a href=\"https://github.com/davidgasquez/dbt-docker/blob/master/Dockerfile\" rel=\"noreferrer\">this dockerfile</a> that can get you started</p>\n<ol start=\"2\">\n<li>\n<blockquote>\n<p>Are logs and the UI from DBT accessible and/or still useful when run via the Docker Operator?</p>\n</blockquote>\n</li>\n</ol>\n<p>Again, it's not a dbt question but rather a docker question or an airflow question.</p>\n<p>Can you see the logs in the airflow UI when using a DockerOperator? Yes, <a href=\"https://marclamberti.com/blog/how-to-use-dockeroperator-apache-airflow/\" rel=\"noreferrer\">see this how to blog post with screenshots</a>.</p>\n<p>Can you access logs from a docker container? Yes, Docker containers emit logs to <code>stdout</code> and <code>stderr</code> output streams (which you can see in airflow, since airflow picks this up). But logs are also stored in JSON files on the host machine in a folder <code>/var/lib/docker/containers/</code>. If you have any advanced needs, you can pick up those logs with a tool (or a simple BashOperator or PythonOperator) and do what you need with it.</p>\n<ol start=\"3\">\n<li>\n<blockquote>\n<p>How would partial pipelines be run? (example: wanting to run only a part of the pipeline)</p>\n</blockquote>\n</li>\n</ol>\n<p>See answer 1, you would run your docker dbt image with the command</p>\n<pre class=\"lang-sh prettyprint-override\"><code>$ docker run my-dbt-image dbt run -m stg_customers\n</code></pre>\n"}, {"owner": {"account_id": 19119069, "reputation": 981, "user_id": 13963390, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a-/AOh14GjyuXth9ZhlTqIsWqs-YeN0og3rSjdK7Sb1yBxc=k-s256", "display_name": "Jeremy Cohen", "link": "https://stackoverflow.com/users/13963390/jeremy-cohen"}, "is_accepted": true, "score": 12, "last_activity_date": 1626730190, "creation_date": 1626730190, "answer_id": 68447240, "question_id": 68439855, "content_license": "CC BY-SA 4.0", "body": "<p>I think it may be this bug: <a href=\"https://github.com/dbt-labs/dbt/issues/3567\" rel=\"noreferrer\">https://github.com/dbt-labs/dbt/issues/3567</a></p>\n<p>That's related to <a href=\"https://docs.getdbt.com/reference/parsing#partial-parsing\" rel=\"noreferrer\">partial parsing</a>, which is a dbt Core performance optimization used in the dbt Cloud IDE. We rebuilt partial parsing from the ground up in v0.20.0, and we'll be including fixes for bugs we uncover (including that one) in v0.20.1.</p>\n<p>In the meantime, if you find yourself in an error state like the one above, you can trigger a full re-parse by deleting the file <code>target/partial_parse.msgpack</code>.</p>\n"}, {"owner": {"account_id": 14897420, "reputation": 381, "user_id": 10757281, "user_type": "registered", "profile_image": "https://graph.facebook.com/10215776085348685/picture?type=large", "display_name": "Reid Williams", "link": "https://stackoverflow.com/users/10757281/reid-williams"}, "is_accepted": false, "score": 12, "last_activity_date": 1631048607, "creation_date": 1631048607, "answer_id": 69094519, "question_id": 69079158, "content_license": "CC BY-SA 4.0", "body": "<p>A conversation on dbt cloud's <a href=\"https://getdbt.slack.com/archives/C2JRRQDTL/p1630952469173300\" rel=\"noreferrer\">slack</a> and a bit of poking and prodding yielded me the answer.</p>\n<p><strong>Yes</strong> you can pass nested macros into a macro much like nested functions in different languages!</p>\n<p>An example could look like this!</p>\n<pre><code>{% macro base_macro(func1, arg1, arg2) %}\n  {{ func1(arg1, arg2) }}\n{% endmacro %}\n</code></pre>\n"}, {"owner": {"account_id": 4727284, "reputation": 5592, "user_id": 3823815, "user_type": "registered", "profile_image": "https://i.sstatic.net/5xNDK.jpg?s=256", "display_name": "louis_guitton", "link": "https://stackoverflow.com/users/3823815/louis-guitton"}, "is_accepted": true, "score": 11, "last_activity_date": 1608724279, "last_edit_date": 1608724279, "creation_date": 1605692115, "answer_id": 64890419, "question_id": 64890144, "content_license": "CC BY-SA 4.0", "body": "<p>My advice would be to leave your dbt and airflow codebases separated.\nThere is indeed a better way:</p>\n<ol>\n<li>dockerise your dbt project in a simple python-based image where you COPY the codebase</li>\n<li>push that to DockerHub or ECR or any other docker repository that you are using</li>\n<li>use the <a href=\"https://airflow.apache.org/docs/apache-airflow-providers-docker/stable/_api/airflow/providers/docker/operators/docker/index.html\" rel=\"noreferrer\"><code>DockerOperator</code></a> in your airflow DAG to run that docker image with your dbt code</li>\n</ol>\n<p>I'm assuming that you use the airflow LocalExecutor here and that you want to execute your <code>dbt run</code> workload on the server where airflow is running. If that's not the case and that you have access to a Kubernetes cluster, I would suggest instead to use the <code>KubernetesPodOperator</code>.</p>\n"}, {"owner": {"account_id": 3690699, "reputation": 2713, "user_id": 3073340, "user_type": "registered", "accept_rate": 95, "profile_image": "https://www.gravatar.com/avatar/114cd763dfcabbe73f1aa28f95a7eb1b?s=256&d=identicon&r=PG&f=y&so-version=2", "display_name": "sgdata", "link": "https://stackoverflow.com/users/3073340/sgdata"}, "is_accepted": false, "score": 11, "last_activity_date": 1651033364, "last_edit_date": 1651033364, "creation_date": 1613485536, "answer_id": 66226249, "question_id": 66224513, "content_license": "CC BY-SA 4.0", "body": "<p>Quoting from the founder's blog post: <a href=\"https://blog.getdbt.com/what--exactly--is-dbt-/\" rel=\"noreferrer\">&quot;What, exactly, is dbt?&quot;</a>,</p>\n<blockquote>\n<p>&quot;dbt is the T in ELT. It doesn\u2019t extract or load data, but it\u2019s\nextremely good at transforming data that\u2019s already loaded into your\nwarehouse. This \u201ctransform after load\u201d architecture is becoming known\nas ELT (extract, load, transform).&quot;</p>\n</blockquote>\n<p>Consequently, unless you already have the api response IN your warehouse, dbt won't be able to help you. You'll probably need an ELT engine (Stitch, Fivetran, Airflow etc. to name a few) to retrieve and store the API response. However, if you have the API response stored as say, a JSON object or a nested string - dbt can work with that.</p>\n<p>It may seem a little underwhelming but the magic of a great product sometimes is it's focus on being really, really great at just one thing.</p>\n<p>Edit 2022: If you are using <code>dbt</code> on a database that supports http or curl function calls and insist on taking this route, I recommend the following <a href=\"https://stackoverflow.com/questions/17407338/how-can-i-make-http-request-from-sql-server\">question</a> as a starting point. Good luck.</p>\n"}, {"owner": {"account_id": 13032007, "reputation": 2260, "user_id": 9418115, "user_type": "registered", "profile_image": "https://i.sstatic.net/6YyIP.png?s=256", "display_name": "Adrien Arcuri", "link": "https://stackoverflow.com/users/9418115/adrien-arcuri"}, "is_accepted": false, "score": 11, "last_activity_date": 1638965052, "creation_date": 1638965052, "answer_id": 70274719, "question_id": 70274718, "content_license": "CC BY-SA 4.0", "body": "<p>It seems that using SQL variables does not work &quot;yet&quot; with dbt.\nYou can use Jinja variable if you want to use static values in multiple places, so that you can rely on Jinja logic.</p>\n<pre><code>{% set myVar = '2017-01-01' %}\n\n...\n\nwhere\n        customer_date &gt; {{myVar}}\n\n...\n</code></pre>\n"}, {"owner": {"account_id": 15981296, "reputation": 2039, "user_id": 11532919, "user_type": "registered", "profile_image": "https://i.sstatic.net/L1j7m.jpg?s=256", "display_name": "Aleix CC", "link": "https://stackoverflow.com/users/11532919/aleix-cc"}, "is_accepted": true, "score": 11, "last_activity_date": 1653316127, "last_edit_date": 1653316127, "creation_date": 1653288096, "answer_id": 72344192, "question_id": 72324405, "content_license": "CC BY-SA 4.0", "body": "<p>As part of <a href=\"https://github.com/dbt-labs/dbt-core/releases/tag/v1.1.0\" rel=\"noreferrer\">dbt-core 1.1.0</a>, we can now <a href=\"https://github.com/dbt-labs/dbt-core/pull/4618\" rel=\"noreferrer\">pass a list to the unique_key statement in incremental models</a>. See the original issue <a href=\"https://github.com/dbt-labs/dbt-core/issues/2479\" rel=\"noreferrer\">here</a>.</p>\n<p>This means that you should be able to achieve your goal by updating <code>dbt-core</code> and your <code>dbt-&lt;adapter&gt;</code> version locally; or updating your dbt Cloud version accordingly, to 1.1.0, since given the error you get, it looks like <code>unique_key</code> is still looking for a single string instead of an array.</p>\n"}, {"owner": {"account_id": 4753087, "reputation": 3892, "user_id": 3842610, "user_type": "registered", "accept_rate": 75, "profile_image": "https://i.sstatic.net/WXMEe.jpg?s=256", "display_name": "Anders Swanson", "link": "https://stackoverflow.com/users/3842610/anders-swanson"}, "is_accepted": false, "score": 10, "last_activity_date": 1642191749, "creation_date": 1642191749, "answer_id": 70716135, "question_id": 70695142, "content_license": "CC BY-SA 4.0", "body": "<p>did you by chance recently upgrade to dbt 1.0.0? If so, this means that you have a model, <code>vGenericView</code> defined in a <code>schema.yml</code> but you don't have a <code>vGenericView.sql</code> model file to which it corresponds.</p>\n"}, {"owner": {"account_id": 3391941, "reputation": 561, "user_id": 2846588, "user_type": "registered", "profile_image": "https://i.sstatic.net/H5rZ9.png?s=256", "display_name": "Stephan", "link": "https://stackoverflow.com/users/2846588/stephan"}, "is_accepted": false, "score": 9, "last_activity_date": 1593827707, "creation_date": 1593827707, "answer_id": 62724533, "question_id": 62710809, "content_license": "CC BY-SA 4.0", "body": "<p>My first guess is that you have a <code>profiles.yml</code> file in your dbt project folder and dbt is not actually using the one in <code>/home/myname/.dbt/</code>.</p>\n<p>Could you try running the following?</p>\n<pre class=\"lang-sh prettyprint-override\"><code>dbt debug --profiles-dir /home/myname/.dbt\n</code></pre>\n<p>The flag <code>--profiles-dir</code> works on most dbt cli commands and lets you use a custom <code>profiles.yml</code> that's outside your project. I use this flag all the time.</p>\n"}], "has_more": true, "quota_max": 300, "quota_remaining": 295}